# Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð¸Ð· ÐºÐ¾Ð½ÑÐ¾Ð»Ð¸
import sys
import logging

logger = logging.getLogger(__name__)
logging.basicConfig(filename="output.log", level=logging.INFO)

def handle_uncaught_exception(exc_type, exc_value, exc_traceback):
    logger.critical(
        "Uncaught exception. Application will terminate.",
        exc_info=(exc_type, exc_value, exc_traceback)
    )

sys.excepthook = handle_uncaught_exception

logger.info("Application started")

#Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ sql Ð² pandas
import pandas as pd 
from pandasql import sqldf

data = {
    'product_id': [1, 2, 1, 3, 2, 3, 1],
    'sale_date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04'],
    'amount': [100, 200, 150, 300, 250, 350, 400]
}

df = pd.DataFrame(data)

# Ð»Ð¾Ð³Ð¸ÐºÐ° Ñ pandas (Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ð´Ð°Ñ‚Ð°Ð¼, Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ product_id, ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚ ÑÑƒÐ¼Ð¼Ñ‹ Ð¿Ð¾ Ð¿Ð¾Ð»ÑŽ amount Ð¸ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ð½ÐµÐ¼Ñƒ Ð¶Ðµ)
result_df = (
    df[df['sale_date'].between('2023-01-02', '2023-01-03')]
    .groupby('product_id', as_index=False)['amount']
    .sum()
    .sort_values(by='amount', ascending=False)
)

# Ð¸Ð»Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÑ sqldf
query = """
    SELECT product_id, SUM(amount) as total_amount
    FROM df
    WHERE sale_date BETWEEN '2023-01-02' AND '2023-01-03'
    GROUP BY product_id
    ORDER BY total_amount DESC
"""

sql_result = sqldf(query, globals())


#Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² Ð‘Ð” Ð¸Ð· Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð°

import pandas as pd
import sqlalchemy as sa

DB = dict(
    user="",
    password="",
    host="",
    port=5432,
    dbname="",
)
engine = sa.create_engine(
    f"postgresql+psycopg2://{DB['user']}:{DB['password']}@{DB['host']}:{DB['port']}/{DB['dbname']}",
)

#  Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ CSV
csv_path   = "big_file.csv"
chunk_rows = 100_000 # Ð±ÑƒÐ´ÐµÐ¼ Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¿Ð¾ 100K ÑÑ‚Ñ€Ð¾Ðº
table_name = "example_csv"
schema     = "raw"

# ÑÐ¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð· Ñ Ð½ÑƒÐ¶Ð½Ñ‹Ð¼Ð¸ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°Ð¼Ð¸
with engine.begin() as conn:
    conn.exec_driver_sql(f"""
        CREATE SCHEMA IF NOT EXISTS {schema};
        DROP TABLE IF EXISTS {schema}.{table_name};
        CREATE TABLE {schema}.{table_name} (
            col_0 text, col_1 text, col_2 text, col_3 text, col_4 text,
            col_5 text, col_6 text, col_7 text, col_8 text, col_9 text
        );
    """)

# Ð³Ñ€ÑƒÐ·Ð¸Ð¼ Ñ‡Ð°Ð½ÐºÐ°Ð¼Ð¸
reader = pd.read_csv(
    csv_path,
    chunksize=chunk_rows,
    iterator=True,
    header=0,
)

for i, chunk in enumerate(reader, 1):
    chunk.to_sql(
        name=table_name,
        con=engine,
        schema=schema,
        if_exists="append",
        index=False,
        method="multi",
    )
    print(f"Ð§Ð°Ð½Ðº {i}: {len(chunk)} ÑÑ‚Ñ€Ð¾Ðº Ð·Ð°Ð»Ð¸Ñ‚Ð¾")

#ÐŸÐ¾Ð¸ÑÐº Ð¿Ð¾ Ñ€ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ñ‹Ð¼ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼ Ð² pandas DF
pattern = r'\b(?:Ð˜Ð˜|Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚|AI|Artificial intelligence|Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚|Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ)\b' 

df_final = df[
    df['title'].str.contains(pattern, case=False, regex=True, na=False) |
    df['domain'].str.contains(pattern, case=False, regex=True, na=False)
]



#Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ð³Ð¾ Ð¿Ð°Ñ€Ð¾Ð»Ñ
import secrets
import string

alphabet = string.ascii_letters + string.digits + "!@#$%^&*"
password = ''.join(secrets.choice(alphabet) for i in range(16))
print(password)

#ÐÐ»ÐµÑ€Ñ‚Ñ‹ Ð² Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼ Ð±Ð¾Ñ‚
python  
requests.post(f"https://api.telegram.org/botTOKEN/sendMessage",  
              json={"chat_id": "ID", "text": "ðŸš¨ CPU > 90%!"})  


